# Pygrad

A small reverse-mode automatic differentiation (backpropagation) and deep learning library built in Python. 

The library is based on the homeworks of CMU'sDeep Learning Systems course (https://github.com/dlsyscourse). Other resources are listed in the references section.

Supports computation of scalar-valued functions composed from a limited set of operations on NumPy arrays. 

The included neural networks module allows the user to define and train deep learning models with a simple API that is similar to PyTorch.

The library is still in development, but the demo notebooks show a few examples of its capabilities as of now. 

### References:

CMU's Deep Learning Systems course: https://github.com/dlsyscourse

PyTorch: https://github.com/pytorch/pytorch

MyGrad: https://github.com/rsokl/MyGrad

TensorFlow: https://github.com/tensorflow/

Adam Optimizer: https://arxiv.org/abs/1412.6980 

Kaiming Initialization: https://arxiv.org/abs/1502.01852

Xavier Initialization: https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf 